/** @jsxImportSource @emotion/react */
import { css } from "@emotion/react";
import styled from "@emotion/styled";
import { useRef, useState, useEffect } from "react";
import { useNavigate } from "react-router-dom";
import NavigationBar from "@/components/NavigationBar";
import PageWrapper from "@/components/PageWrapper";
import imgPath from "@/assets/eyes_open_nobg.png";
import { useVoicePref } from "@/store/useVoicePref";

const Title = styled.h2`
  margin: 0 0 clamp(2vh, 3.2vh, 4vh) 0;
  font-size: clamp(3.5vh, 3.5vh, 3.5vh);
  line-height: 1.2;
`;

const ButtonGroup = styled.div`
  display: flex;
  flex-direction: column;
  gap: clamp(1.6vh, 2vh, 2.4vh);
`;

const UploadButton = styled.button`
  padding: clamp(1.6vh, 2.2vh, 2.8vh) clamp(2vh, 2.6vh, 3.2vh);
  font-size: clamp(2vh, 2vh, 2vh);
  border-radius: clamp(1vh, 1.4vh, 1.8vh);
  border: 0.25vh solid #d1d1d6;
  background-color: #f9f9f9;
  cursor: pointer;
  transition: background-color 0.2s ease-in-out, transform 0.06s ease;
  text-align: center;

  &:hover { background-color: #eaeaea; }
  &:active { transform: translateY(0.3vh); }
  @media (prefers-reduced-motion: reduce) {
    transition: none;
  }
`;

const PreviewWrap = styled.div`
  margin-top: clamp(2.4vh, 3.2vh, 4vh);
  text-align: center;
`;

const PreviewImage = styled.img`
  width: 100%;
  max-width: 60vh;
  border-radius: clamp(1vh, 1.4vh, 1.8vh);
  display: block;
  margin: 0 auto;
`;

// ============================
// Camera Page
// ============================
const CameraPage = () => {
  const { enabled } = useVoicePref();
  return enabled ? <CameraVoiceMode /> : <CameraManualMode />;
};

export default CameraPage;

/* ============================
   ìŒì„± ëª¨ë“œ
============================ */
const CameraVoiceMode = () => {
  const [imagePreview, setImagePreview] = useState<string | null>(null);
  const inputRef = useRef<HTMLInputElement | null>(null);
  const navigate = useNavigate();

  const recognitionRef = useRef<any>(null);
  const startedRef = useRef(false);

  // --- ë³´ì´ìŠ¤ ìœ í‹¸
  const awaitVoices = () =>
    new Promise<void>((resolve) => {
      try {
        const synth = window.speechSynthesis;
        const ready = () => {
          const v = synth.getVoices();
          if (v && v.length > 0) { resolve(); return true; }
          return false;
        };
        if (ready()) return;
        synth.onvoiceschanged = () => { if (ready()) synth.onvoiceschanged = null as any; };
        setTimeout(() => resolve(), 1500);
      } catch { resolve(); }
    });

  const pickKoreanVoice = () => {
    try {
      const voices = window.speechSynthesis.getVoices() || [];
      return (
        voices.find(v => v.lang?.toLowerCase() === "ko-kr") ||
        voices.find(v => v.lang?.toLowerCase().startsWith("ko")) ||
        null
      );
    } catch { return null; }
  };

  const speakAndThen = async (text: string, then?: () => void) => {
    let finished = false;
    const done = () => { if (finished) return; finished = true; try { then?.(); } catch {} };
    const SAFETY_MS = 4000;
    const timer = setTimeout(done, SAFETY_MS);

    try {
      await awaitVoices();
      try { window.speechSynthesis.resume(); } catch {}
      await new Promise(r => setTimeout(r, 120));

      const u = new SpeechSynthesisUtterance(text);
      u.lang = "ko-KR";
      const v = pickKoreanVoice(); if (v) u.voice = v;
      u.onend = () => { clearTimeout(timer); setTimeout(done, 80); };

      try { window.speechSynthesis.cancel(); } catch {}
      window.speechSynthesis.speak(u);
    } catch {
      clearTimeout(timer);
      done();
    }
  };

  // --- íŒŒì¼ ì„ íƒ í•¸ë“¤ëŸ¬
  const handleImageChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      const reader = new FileReader();
      reader.onloadend = () => setImagePreview(reader.result as string);
      reader.readAsDataURL(file);
    }
  };

  const handleRegisterDocument = () => {
    if (!imagePreview) {
      alert("ì‚¬ì§„ì„ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”!");
      return;
    }
    console.log("ì„œë¥˜ ë“±ë¡ ì²˜ë¦¬ ì¤‘...");
  };

  // --- ìŒì„± ì¸ì‹ ë£¨í”„
  const startListening = () => {
    const SR = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (!SR) {
      speakAndThen("ì´ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    try { recognitionRef.current?.stop(); } catch {}
    recognitionRef.current = null;

    const rec = new SR();
    recognitionRef.current = rec;
    rec.lang = "ko-KR";
    rec.interimResults = false;
    rec.maxAlternatives = 1;

    rec.onresult = async (event: any) => {
      const raw = (event?.results?.[0]?.[0]?.transcript ?? "").trim();
      const low = raw.replace(/\s+/g, "").toLowerCase();
      if (!raw) return;

      if (low.includes("ì‚¬ì§„") || low.includes("ì´¬ì˜")) {
        await speakAndThen("ì‚¬ì§„ ì´¬ì˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.", () => {
          inputRef.current?.click();
        });
        return;
      }
      if (low.includes("ì—…ë¡œë“œ")) {
        await speakAndThen("ì„œë¥˜ ì—…ë¡œë“œ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.", () => {
          navigate("/document-scan");
        });
        return;
      }
      if (low.includes("ì§ì ‘") || low.includes("ë“±ë¡")) {
        await speakAndThen("ì§ì ‘ ë“±ë¡ í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤.", () => {
          navigate("/manual-register");
        });
        return;
      }

      await speakAndThen(
        "ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì‚¬ì§„ ì´¬ì˜í•˜ê¸°, ì„œë¥˜ ì—…ë¡œë“œí•˜ê¸°, ì§ì ‘ ë“±ë¡í•˜ê¸° ì¤‘ì—ì„œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
        () => startListening()
      );
    };

    rec.onerror = async () => {
      await speakAndThen("ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", () => startListening());
    };

    rec.onend = () => {
      if (!window.speechSynthesis.speaking) {
        try { rec.start(); } catch {}
      }
    };

    try { rec.start(); } catch {}
  };

  useEffect(() => {
    if (startedRef.current) return;
    startedRef.current = true;

    const intro = async () => {
      await speakAndThen("ì„œë¥˜ ë“±ë¡ í˜ì´ì§€ì…ë‹ˆë‹¤. ì‚¬ì§„ ì´¬ì˜í•˜ê¸°, ì„œë¥˜ ì—…ë¡œë“œí•˜ê¸°, ì§ì ‘ ë“±ë¡í•˜ê¸° ì¤‘ í•˜ë‚˜ë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”.", () => startListening());
    };
    intro();

    return () => {
      try { recognitionRef.current?.stop(); } catch {}
      try { window.speechSynthesis.cancel(); } catch {}
    };
  }, []);

  return (
    <>
      <NavigationBar brandName="ì²«ëˆˆ" imageSrcPath={imgPath} />
      <PageWrapper>
        <Title>ğŸ“‚ ì„œë¥˜ ë“±ë¡ (ìŒì„± ëª¨ë“œ)</Title>

        <input
          ref={inputRef}
          type="file"
          accept="image/*"
          capture="environment"
          style={{ display: "none" }}
          onChange={handleImageChange}
        />

        <ButtonGroup>
          <UploadButton onClick={() => navigate("/document-scan")}>ğŸ–¼ï¸ ì„œë¥˜ ì—…ë¡œë“œí•˜ê¸°</UploadButton>
          <UploadButton onClick={() => inputRef.current?.click()}>ğŸ“· ì‚¬ì§„ ì´¬ì˜í•˜ê¸°</UploadButton>
          <UploadButton onClick={() => navigate("/manual-register")}>âœï¸ ì§ì ‘ ë“±ë¡í•˜ê¸°</UploadButton>
        </ButtonGroup>

        {imagePreview && (
          <PreviewWrap>
            <PreviewImage src={imagePreview} alt="ë¯¸ë¦¬ë³´ê¸°" />
            <UploadButton
              onClick={handleRegisterDocument}
              css={css`margin-top: clamp(2vh, 2.6vh, 3.2vh); width: 100%; max-width: 60vh;`}
            >
              ğŸ“„ ì„œë¥˜ ë“±ë¡í•˜ê¸°
            </UploadButton>
          </PreviewWrap>
        )}
      </PageWrapper>
    </>
  );
};

/* ============================
   ìˆ˜ë™ ëª¨ë“œ
============================ */
const CameraManualMode = () => {
  const [imagePreview, setImagePreview] = useState<string | null>(null);
  const inputRef = useRef<HTMLInputElement | null>(null);
  const navigate = useNavigate();

  const handleImageChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      const reader = new FileReader();
      reader.onloadend = () => setImagePreview(reader.result as string);
      reader.readAsDataURL(file);
    }
  };

  const handleRegisterDocument = () => {
    if (!imagePreview) {
      alert("ì‚¬ì§„ì„ ë¨¼ì € ë“±ë¡í•´ì£¼ì„¸ìš”!");
      return;
    }
    console.log("ì„œë¥˜ ë“±ë¡ ì²˜ë¦¬ ì¤‘...");
  };

  return (
    <>
      <NavigationBar brandName="ì²«ëˆˆ" imageSrcPath={imgPath} />
      <PageWrapper>
        <Title>ğŸ“‚ ì„œë¥˜ ë“±ë¡</Title>

        <input
          ref={inputRef}
          type="file"
          accept="image/*"
          capture="environment"
          style={{ display: "none" }}
          onChange={handleImageChange}
        />

        <ButtonGroup>
          <UploadButton onClick={() => navigate("/document-scan")}>ğŸ–¼ï¸ ì„œë¥˜ ì—…ë¡œë“œí•˜ê¸°</UploadButton>
          <UploadButton onClick={() => inputRef.current?.click()}>ğŸ“· ì‚¬ì§„ ì´¬ì˜í•˜ê¸°</UploadButton>
          <UploadButton onClick={() => navigate("/manual-register")}>âœï¸ ì§ì ‘ ë“±ë¡í•˜ê¸°</UploadButton>
        </ButtonGroup>

        {imagePreview && (
          <PreviewWrap>
            <PreviewImage src={imagePreview} alt="ë¯¸ë¦¬ë³´ê¸°" />
            <UploadButton
              onClick={handleRegisterDocument}
              css={css`margin-top: clamp(2vh, 2.6vh, 3.2vh); width: 100%; max-width: 60vh;`}
            >
              ğŸ“„ ì„œë¥˜ ë“±ë¡í•˜ê¸°
            </UploadButton>
          </PreviewWrap>
        )}
      </PageWrapper>
    </>
  );
};
